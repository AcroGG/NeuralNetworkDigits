{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data and split into training and dev sets  shuffle data\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) \n",
    "\n",
    "dev_data = data[0:1000].T\n",
    "dev_y = dev_data[0]\n",
    "dev_x = dev_data[1:n]\n",
    "dev_x = dev_x / 255.\n",
    "\n",
    "train_data = data[1000:m].T\n",
    "train_y = train_data[0]\n",
    "train_x = train_data[1:n]\n",
    "train_x = train_x / 255.\n",
    "_,m_train = train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weight and bias parameters \n",
    "# Create math activation functions layers will be applied too\n",
    "# Create forward propagation function activation functions, weights and biases are applied to layers to use image data to predict image digit\n",
    "# Create a backwards propagation function that uses the actual correct digit to cross check with the predictions and measures how much the weights and biases contribute to how incorrect it is \n",
    "# finally update parameters \n",
    "def init_params():\n",
    "    Weight1 = np.random.rand(10, 784) - 0.5\n",
    "    bias1 = np.random.rand(10, 1) - 0.5\n",
    "    Weight2 = np.random.rand(10, 10) - 0.5\n",
    "    bias2 = np.random.rand(10, 1) - 0.5\n",
    "    return Weight1, bias1, Weight2, bias2\n",
    "\n",
    "def ReLU(Unactivated_layer):\n",
    "    return np.maximum(Unactivated_layer, 0)\n",
    "\n",
    "def softmax(Unactivated_layer):\n",
    "    return np.exp(Unactivated_layer) / sum(np.exp(Unactivated_layer))\n",
    "    \n",
    "def forward_propagation(Weight1, bias1, Weight2, bias2, x):\n",
    "    Unactivated_layer_1 = Weight1.dot(x) + bias1\n",
    "    Input_layer_1 = ReLU(Unactivated_layer_1)\n",
    "    Unactivated_layer_2 = Weight2.dot(Input_layer_1) + bias2\n",
    "    Input_layer_2 = softmax(Unactivated_layer_2)\n",
    "    return Unactivated_layer_1, Input_layer_1, Unactivated_layer_2, Input_layer_2\n",
    "\n",
    "def ReLU_deriv(Unactivated_layer):\n",
    "    return Unactivated_layer > 0\n",
    "\n",
    "#used to encode the label actual digits row\n",
    "def digit_encode(y):\n",
    "    encode_y = np.zeros((y.size, y.max() + 1))\n",
    "    encode_y[np.arange(y.size), y] = 1\n",
    "    encode_y = encode_y.T\n",
    "    return encode_y\n",
    "\n",
    "def backward_propagation(Unactivated_layer_1, Input_layer_1, Unactivated_layer_2, Input_layer_2, Weight1, Weight2, x, y):\n",
    "    encode_y = digit_encode(y)\n",
    "    dU2 = Input_layer_2 - encode_y\n",
    "    dWeight2 = 1 / m * dU2.dot(Input_layer_1.T)\n",
    "    dbias2 = 1 / m * np.sum(dU2)\n",
    "    dU1 = Weight2.T.dot(dU2) * ReLU_deriv(Unactivated_layer_1)\n",
    "    dWeight1 = 1 / m * dU1.dot(x.T)\n",
    "    dbias1 = 1 / m * np.sum(dU1)\n",
    "    return dWeight1, dbias1, dWeight2, dbias2\n",
    "\n",
    "def update_params(Weight1, bias1, Weight2, bias2, dWeight1, dbias1, dWeight2, dbias2, alpha):\n",
    "    Weight1 = Weight1 - alpha * dWeight1\n",
    "    bias1 = bias1 - alpha * dbias1    \n",
    "    Weight2 = Weight2 - alpha * dWeight2  \n",
    "    bias2 = bias2 - alpha * dbias2    \n",
    "    return Weight1, bias1, Weight2, bias2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the function together as a learning model iterate through the data and get accuracy\n",
    "def get_predictions(Input_layer_2):\n",
    "    return np.argmax(Input_layer_2, 0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    print(predictions, y)\n",
    "    return np.sum(predictions == y) / y.size\n",
    "\n",
    "def learning_model(x, y, alpha, iterations):\n",
    "    Weight1, bias1, Weight2, bias2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Unactivated_layer_1, Input_layer_1, Unactivated_layer_2, Input_layer_2 = forward_propagation(Weight1, bias1, Weight2, bias2, x)\n",
    "        dWeight1, dbias1, dWeight2, dbias2 = backward_propagation(Unactivated_layer_1, Input_layer_1, Unactivated_layer_2, Input_layer_2, Weight1, Weight2, x, y)\n",
    "        Weight1, bias1, Weight2, bias2 = update_params(Weight1, bias1, Weight2, bias2, dWeight1, dbias1, dWeight2, dbias2, alpha)\n",
    "        if i % 50 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(Input_layer_2)\n",
    "            print(\"Accuracy: \", get_accuracy(predictions, y))\n",
    "    return Weight1, bias1, Weight2, bias2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[4 6 6 ... 7 7 8] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.08857627118644068\n",
      "Iteration:  50\n",
      "[4 2 4 ... 2 3 8] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.26552542372881355\n",
      "Iteration:  100\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.5146440677966102\n",
      "Iteration:  150\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.6391016949152543\n",
      "Iteration:  200\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.7176610169491525\n",
      "Iteration:  250\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.7628983050847458\n",
      "Iteration:  300\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.7903559322033898\n",
      "Iteration:  350\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.807677966101695\n",
      "Iteration:  400\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.819728813559322\n",
      "Iteration:  450\n",
      "[4 1 9 ... 2 3 3] [4 1 9 ... 2 5 3]\n",
      "Accuracy:  0.8285423728813559\n"
     ]
    }
   ],
   "source": [
    "Weight1, bias1, Weight2, bias2 = learning_model(train_x, train_y, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally make and test prediction from image data using layers weights and biases\n",
    "# Display prediction and data image\n",
    "\n",
    "def make_predictions(x, Weight1, bias1, Weight2, bias2):\n",
    "    _, _, _, Input_layer_2 = forward_propagation(Weight1, bias1, Weight2, bias2, x)\n",
    "    predictions = get_predictions(Input_layer_2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, Weight1, bias1, Weight2, bias2):\n",
    "    current_image = train_x[:, index, None]\n",
    "    prediction = make_predictions(train_x[:, index, None], Weight1,bias1,Weight2,bias2)\n",
    "    label = train_y[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "\n",
    "    current_image = current_image.reshape((28,28)) *255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [9]\n",
      "Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(2, Weight1, bias1, Weight2, bias2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
